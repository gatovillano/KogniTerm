import os
from researcher_crew import ResearcherCrew
# Asumimos que el entorno ya tiene configuradas las variables para el LLM 
# que usa KogniTerm (ej. OpenAI, Anthropic, etc.)
from langchain_openai import ChatOpenAI 

def run_test():
    print("üöÄ Iniciando prueba del nuevo ResearcherAgent Multi-Agente...")
    
    # 1. Configurar el LLM (usando los est√°ndares de la app)
    # Por defecto CrewAI busca OPENAI_API_KEY, pero aqu√≠ lo explicitamos
    llm = ChatOpenAI(
        model=os.environ.get("OPENAI_MODEL_NAME", "gpt-4-turbo-preview"),
        temperature=0.2
    )

    # 2. Instanciar la Crew
    crew_orchestrator = ResearcherCrew(llm)

    # 3. Definir una consulta de prueba t√©cnica
    query = "Analizar la estructura actual de los agentes en el directorio \'agents/\' y proponer mejoras de modularidad."

    print(f"üîç Investigando: {query}\n")
    
    # 4. Ejecutar el proceso
    result = crew_orchestrator.run(query)

    # 5. Guardar el resultado
    output_file = "test_environment/final_report.md"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(result)

    print(f"\n‚úÖ Prueba completada con √©xito!")
    print(f"üìÑ Informe generado en: {output_file}")

if __name__ == "__main__":
    run_test()
