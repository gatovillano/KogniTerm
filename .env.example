# ---------------------------------------------------
# CONFIGURACIÓN DEL PROVEEDOR DE LLM
# ---------------------------------------------------
# Elige el proveedor: "openai" para endpoints compatibles con OpenAI, o "google" para Gemini.
LLM_PROVIDER="openai"

# --- Configuración para LLM_PROVIDER="openai" ---
# Descomenta y rellena estas líneas si usas un proveedor compatible con OpenAI.
# Requerido: El modelo a utilizar (ej: "llama3-8b-8192", "mixtral-8x7b-32768").
LLM_MODEL="aqui_va_el_nombre_de_tu_modelo"
# Requerido: Tu clave de API para el proveedor.
LLM_API_KEY="aqui_va_tu_api_key"
# Opcional, pero recomendado: El endpoint de la API de tu proveedor.
# Si usas el API oficial de OpenAI, puedes dejar esta línea comentada.
LLM_API_ENDPOINT="https://api.tu-proveedor.com/v1"


# --- Configuración para LLM_PROVIDER="google" ---
# Descomenta y rellena estas líneas si usas Google Gemini.
# GOOGLE_API_KEY="aqui_va_tu_google_api_key"
# GEMINI_MODEL="gemini-1.5-flash"
