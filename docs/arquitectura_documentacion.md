# An√°lisis T√©cnico de la Arquitectura de KogniTerm üïµÔ∏è‚Äç‚ôÇÔ∏è

## Introducci√≥n
Este documento presenta un an√°lisis t√©cnico detallado de la arquitectura interna de KogniTerm. A trav√©s de una exploraci√≥n exhaustiva de su c√≥digo fuente, se describen los componentes fundamentales que permiten la orquestaci√≥n de agentes, la ejecuci√≥n segura de herramientas y los mecanismos de persistencia y recuperaci√≥n de informaci√≥n (RAG) que definen el funcionamiento del sistema.

---

## 1. Grafo de Estados de LangGraph (Orquestaci√≥n de Agentes) üß¨

KogniTerm utiliza un modelo de grafo de estados definido mediante `langgraph.graph.StateGraph`. La orquestaci√≥n principal se encuentra en `kogniterm/core/agents/bash_agent.py`.

### Estructura del Grafo

El flujo de trabajo es un bucle interactivo dise√±ado para manejar la generaci√≥n de texto y la ejecuci√≥n de herramientas de forma c√≠clica:

```mermaid
graph TD
    START((Inicio)) --> call_model[Nodo: call_model]
    call_model --> should_continue{should_continue?}
    should_continue -- "execute_tool" --> execute_tool[Nodo: execute_tool]
    execute_tool --> call_model
    should_continue -- "END" --> END((Fin))
    
    subgraph "Mecanismo de Confirmaci√≥n"
    execute_tool -- "requires_confirmation" --> END
    end
```

*   **call_model**: Env√≠a el historial al LLM (v√≠a `LLMService.invoke`). Soporta streaming en tiempo real y detecta si el modelo solicita herramientas (`tool_calls`).
*   **execute_tool**: Ejecuta las herramientas en paralelo usando un `ThreadPoolExecutor`. Si una herramienta devuelve un estado `requires_confirmation`, el grafo se detiene inmediatamente.
*   **should_continue**: L√≥gica condicional que decide si volver al modelo (tras recibir el output de una herramienta) o terminar el turno (si hay texto final o se requiere confirmaci√≥n del usuario).

---

## 2. Estructura Exacta de las Herramientas (API Interna) üõ†Ô∏è

Las herramientas est√°n construidas sobre `langchain_core.tools.BaseTool` y utilizan `pydantic` para la validaci√≥n de esquemas.

### execute_command

*   **Archivo**: `kogniterm/core/tools/execute_command_tool.py`
*   **Entrada (ExecuteCommandInput)**:
    *   `command` (string): El comando bash exacto a ejecutar.
*   **Salida**: Un generador que cede (`yield`) la salida est√°ndar (stdout/stderr) en tiempo real.
*   **Seguridad**: No se ejecuta directamente en el nodo; el grafo detecta la llamada y delega la ejecuci√≥n al `CommandApprovalHandler` para solicitar permiso al usuario.

### advanced_file_editor

*   **Archivo**: `kogniterm/core/tools/advanced_file_editor_tool.py`
*   **Entrada (AdvancedFileEditorInput)**:
    *   `path` (string): Ruta del archivo.
    *   `action` (string): `insert_line`, `replace_regex`, `prepend_content`, `append_content`.
    *   `content / replacement_content` (string): El texto a insertar o el reemplazo.
    *   `regex_pattern` (string, opcional): Para la acci√≥n `replace_regex`.
    *   `line_number` (int, opcional): Para `insert_line`.
    *   `confirm` (bool, default `False`): Flag cr√≠tico para la re-ejecuci√≥n tras aprobaci√≥n.
*   **Salida**: Un diccionario con `status: "requires_confirmation"`, un `diff` unificado y los `args` necesarios para re-ejecutar la acci√≥n.

### codebase_search_tool (RAG)

*   **Archivo**: `kogniterm/core/tools/codebase_search_tool.py`
*   **Entrada (CodebaseSearchToolArgs)**:
    *   `query` (string): Consulta sem√°ntica.
    *   `k` (int, default 5): N√∫mero de fragmentos a recuperar.
    *   `file_path_filter` (string, opcional): Filtro de ruta.
    *   `language_filter` (string, opcional): Filtro por lenguaje (ej. 'python').
*   **Salida**: Un string formateado con los fragmentos de c√≥digo m√°s relevantes, incluyendo metadatos (archivo, l√≠neas, lenguaje).

---

## 3. Persistencia de Memoria y RAG (ChromaDB) üß†

KogniTerm implementa un sistema de memoria de dos capas:

### Memoria Contextual (llm_context.md)

*   **Ubicaci√≥n**: `.kogniterm/llm_context.md` (dentro del proyecto actual).
*   **Funcionamiento**: Las herramientas `memory_append` y `memory_read` permiten al agente persistir hechos, decisiones o estructuras del proyecto que el LLM debe recordar entre sesiones. Es una memoria de "largo plazo" basada en texto plano.

### Integraci√≥n RAG con ChromaDB

*   **Motor**: `chromadb.PersistentClient` ubicado en `.kogniterm/vector_db/`.
*   **Indexaci√≥n**: `VectorDBManager` gestiona la colecci√≥n `codebase_chunks`. El c√≥digo se divide en fragmentos (`chunks`) con metadatos (l√≠neas, archivo, tipo de bloque).
*   **Embeddings**: Utiliza `EmbeddingsService` para convertir texto en vectores.
*   **Flujo de B√∫squeda**:
    1. El usuario pregunta algo t√©cnico.
    2. `codebase_search_tool` genera un embedding de la consulta.
    3. `ChromaDB` realiza una b√∫squeda por similitud de coseno (o distancia L2).
    4. Los resultados se inyectan en el prompt del agente como contexto.

---

## 4. Protocolos de Seguridad y Confirmaci√≥n üõ°Ô∏è

La seguridad es un pilar central de KogniTerm, implementada mediante un sistema de "Interrupci√≥n y Re-entrada".

### Flujo de Confirmaci√≥n

1.  **Detecci√≥n**: Cuando una herramienta (como `execute_command` o `advanced_file_editor`) se invoca, el sistema detecta que es una operaci√≥n "sensible".
2.  **Estado de Suspensi√≥n**: El nodo de ejecuci√≥n lanza una excepci√≥n `UserConfirmationRequired` o devuelve un estado `requires_confirmation`.
3.  **Intervenci√≥n de la Terminal**: El `CommandApprovalHandler` (en `kogniterm/terminal/command_approval_handler.py`) captura este estado, genera una explicaci√≥n del comando usando el LLM y presenta un panel visual al usuario.
4.  **Aprobaci√≥n/Denegaci√≥n**:
    *   Si el usuario dice 's': Se re-invoca la herramienta con el par√°metro `confirm=True`.
    *   Si el usuario dice 'n': Se a√±ade un `AIMessage` al historial indicando que la acci√≥n fue denegada, permitiendo al agente razonar sobre el rechazo.

---

## 5. L√≥gica de Delegaci√≥n entre Agentes ü§ù

KogniTerm utiliza un modelo de Delegaci√≥n Jer√°rquica mediante la herramienta `call_agent`.

### BashAgent -> ResearcherAgent

1.  **Invocaci√≥n**: El `BashAgent` (agente principal) decide que una tarea requiere una investigaci√≥n profunda que no implica necesariamente ejecutar comandos bash (ej. "Entiende c√≥mo funciona la autenticaci√≥n en este proyecto").
2.  **Herramienta call_agent**: Se llama a esta herramienta con `agent_name="researcher_agent"` y la `task` espec√≠fica.
3.  **Aislamiento de Grafo**: `call_agent` crea una instancia fresca del `ResearcherAgent` con su propio grafo y su propio `SYSTEM_MESSAGE` (el de "Detective de C√≥digo").
4.  **Transferencia de Contexto**: Se le pasa la tarea como un `HumanMessage` inicial. El `ResearcherAgent` ejecuta su propio bucle de investigaci√≥n (usando RAG y lectura de archivos).
5.  **S√≠ntesis y Retorno**: Al terminar, el `ResearcherAgent` devuelve un resumen de sus hallazgos. Este resumen se entrega al `BashAgent` como el output de la herramienta `call_agent`, permitiendo al agente principal continuar con la ejecuci√≥n basada en la investigaci√≥n.

---

### Observaciones de Arquitectura ("Code Smells" e Inconsistencias)

*   **Duplicidad de Streaming**: Se observ√≥ que tanto el nodo del grafo como el `LLMService` manejan l√≥gica de streaming, lo que requiere un filtrado cuidadoso de `AIMessage` para no duplicar contenido en el historial.
*   **Sincronizaci√≥n de Historial**: El historial se guarda en disco (`history.json`) de forma agresiva en cada nodo para evitar p√©rdida de datos ante interrupciones, lo cual es robusto pero puede impactar el rendimiento en proyectos con historiales masivos.

---
**Informe realizado por el ResearchAgent de KogniTerm. üïµÔ∏è‚Äç‚ôÇÔ∏èüìë**
